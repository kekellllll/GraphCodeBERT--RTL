# RTLæ¨¡å‹è®­ç»ƒæ•°æ®æºè¯´æ˜ / RTL Model Training Data Sources

## ä¸­æ–‡è¯´æ˜

### ğŸ” ç”¨æˆ·é—®é¢˜å›ç­”
**é—®é¢˜**: è¿™ä¸ªRTLæ¨¡å‹è®­ç»ƒæ²¡æœ‰æ•°æ®ä¹ˆï¼Œè¿™äº›æµ‹è¯•çš„è¾“å‡ºæ˜¯è®­ç»ƒçš„ç»“æœè¿˜æ˜¯ä½ è‡ªå·±æ·»åŠ çš„ï¼Ÿå¦‚æœæœ‰æ•°æ®é›†è¯·å‘Šè¯‰æˆ‘å…·ä½“åœ¨å“ªé‡Œï¼Ÿ

**å›ç­”**:

### âœ… å½“å‰æ•°æ®çŠ¶å†µ
1. **ç°æœ‰æ•°æ®ç±»å‹**: ç›®å‰é¡¹ç›®ä¸­ä½¿ç”¨çš„æ˜¯**æ¼”ç¤ºæ ·æœ¬æ•°æ®**ï¼Œä¸æ˜¯çœŸå®çš„å¤§è§„æ¨¡è®­ç»ƒæ•°æ®é›†
2. **æ•°æ®ä½ç½®**: ç¡¬ç¼–ç åœ¨ `GraphCodeBERT/rtl_error_localization/rtl_error_correction.py` çš„ `create_sample_data()` å‡½æ•°ä¸­
3. **æ•°æ®è§„æ¨¡**: ä»…æœ‰3ä¸ªåŸºç¡€ç¤ºä¾‹ï¼Œç”¨äºåŠŸèƒ½æ¼”ç¤ºå’Œä»£ç éªŒè¯
4. **æµ‹è¯•è¾“å‡º**: å½“å‰çš„æµ‹è¯•è¾“å‡ºæ˜¯åŸºäºè¿™äº›é¢„å®šä¹‰æ ·æœ¬ï¼Œ**ä¸æ˜¯**çœŸå®è®­ç»ƒçš„ç»“æœ

### ğŸ“Š å…·ä½“æ•°æ®å†…å®¹
```python
# ä½ç½®: GraphCodeBERT/rtl_error_localization/rtl_error_correction.py:255-274
def create_sample_data():
    examples = [
        {
            'buggy_code': 'module test(input a, output b); assign b = a + 1; endmodule',
            'correct_code': 'module test(input a, output b); assign b = a; endmodule',
            'comments': 'Simple wire connection module'
        },
        # ... å¦å¤–2ä¸ªç±»ä¼¼ç¤ºä¾‹
    ]
```

### ğŸ¯ é¡¹ç›®ç°çŠ¶
- **ç›®çš„**: è¿™æ˜¯ä¸€ä¸ª**æ¦‚å¿µéªŒè¯å’Œæ¡†æ¶å®ç°**ï¼Œå±•ç¤ºå¦‚ä½•å°†GraphCodeBERTé€‚é…åˆ°RTLé”™è¯¯ä¿®æ­£ä»»åŠ¡
- **å®ç°çŠ¶æ€**: å®Œæ•´çš„æ¨¡å‹æ¶æ„å’Œå¤„ç†æµç¨‹ï¼Œä½†ç¼ºå°‘å¤§è§„æ¨¡è®­ç»ƒæ•°æ®
- **åŠŸèƒ½éªŒè¯**: æ‰€æœ‰åŠŸèƒ½éƒ½å¯ä»¥è¿è¡Œï¼Œä½†åŸºäºå°è§„æ¨¡æ ·æœ¬æ•°æ®

### ğŸ“ æ•°æ®é›†éœ€æ±‚å’Œåˆ›å»ºæŒ‡å—

#### çœŸå®è®­ç»ƒæ•°æ®é›†åº”åŒ…å«:
1. **é”™è¯¯RTLä»£ç **: åŒ…å«å„ç§è¯­æ³•å’Œé€»è¾‘é”™è¯¯çš„Verilogä»£ç 
2. **æ­£ç¡®RTLä»£ç **: å¯¹åº”çš„ä¿®æ­£ç‰ˆæœ¬
3. **æ³¨é‡Šä¿¡æ¯**: ä»£ç åŠŸèƒ½è¯´æ˜
4. **æ•°æ®æµå›¾**: è‡ªåŠ¨æå–çš„DFGä¿¡æ¯
5. **é”™è¯¯ä½ç½®**: ç²¾ç¡®çš„é”™è¯¯å®šä½ä¿¡æ¯

#### æ¨èçš„æ•°æ®é›†å¤§å°:
- **è®­ç»ƒé›†**: è‡³å°‘10,000ä¸ªé”™è¯¯-ä¿®æ­£ä»£ç å¯¹
- **éªŒè¯é›†**: 2,000ä¸ªä»£ç å¯¹
- **æµ‹è¯•é›†**: 2,000ä¸ªä»£ç å¯¹

---

## English Explanation

### ğŸ” User Question Response
**Question**: Does this RTL model training have no data? Are these test outputs the result of training or did you add them yourself? If there are datasets, please tell me specifically where they are?

**Answer**:

### âœ… Current Data Status
1. **Data Type**: The project currently uses **demonstration sample data**, not real large-scale training datasets
2. **Data Location**: Hard-coded in the `create_sample_data()` function in `GraphCodeBERT/rtl_error_localization/rtl_error_correction.py`
3. **Data Scale**: Only 3 basic examples for functionality demonstration and code validation
4. **Test Output**: Current test outputs are based on these predefined samples, **NOT** real training results

### ğŸ“Š Specific Data Content
The sample data consists of 3 hardcoded examples:
- Module with unnecessary arithmetic operation
- Always block with incorrect assignment
- Logic expression missing parentheses

### ğŸ¯ Project Status
- **Purpose**: This is a **proof-of-concept and framework implementation** showing how to adapt GraphCodeBERT for RTL error correction
- **Implementation Status**: Complete model architecture and processing pipeline, but lacking large-scale training data
- **Functionality**: All functions work, but based on small sample data

### ğŸ“ Dataset Requirements and Creation Guide

#### Real Training Dataset Should Include:
1. **Buggy RTL Code**: Verilog code with various syntax and logic errors
2. **Correct RTL Code**: Corresponding corrected versions
3. **Comments**: Code functionality descriptions
4. **Data Flow Graphs**: Automatically extracted DFG information
5. **Error Locations**: Precise error localization information

#### Recommended Dataset Size:
- **Training Set**: At least 10,000 error-correction code pairs
- **Validation Set**: 2,000 code pairs
- **Test Set**: 2,000 code pairs

---

## ğŸ› ï¸ å¦‚ä½•åˆ›å»ºçœŸå®æ•°æ®é›† / How to Create Real Datasets

### æ–¹æ³•ä¸€: æ‰‹åŠ¨æ ‡æ³¨ / Method 1: Manual Annotation
```bash
# åˆ›å»ºæ•°æ®é›†ç›®å½•
mkdir -p datasets/rtl_error_correction/{train,valid,test}

# æ•°æ®æ ¼å¼ç¤ºä¾‹ (datasets/rtl_error_correction/train/sample.jsonl)
{"buggy_code": "module ...", "correct_code": "module ...", "comments": "...", "error_type": "syntax"}
```

### æ–¹æ³•äºŒ: è‡ªåŠ¨ç”Ÿæˆ / Method 2: Automatic Generation
```bash
# è¿è¡Œæ•°æ®ç”Ÿæˆå·¥å…·
python tools/generate_rtl_dataset.py --output datasets/rtl_error_correction --size 10000
```

### æ–¹æ³•ä¸‰: ç°æœ‰æ•°æ®é›†é€‚é… / Method 3: Existing Dataset Adaptation
- å¯»æ‰¾ç°æœ‰çš„Verilogä»£ç é”™è¯¯æ•°æ®é›†
- é€‚é…åˆ°é¡¹ç›®è¦æ±‚çš„æ ¼å¼
- æ·»åŠ DFGæå–å’Œé”™è¯¯ä½ç½®æ ‡æ³¨

---

## ğŸ“ ä½¿ç”¨ç°æœ‰æ ·æœ¬æ•°æ®è¿›è¡Œæµ‹è¯• / Testing with Current Sample Data

```bash
# è¿è¡Œæ¼”ç¤º (åŸºäºæ ·æœ¬æ•°æ®)
cd GraphCodeBERT/rtl_error_localization
python demo_rtl_error_correction.py

# è¿è¡Œç¦»çº¿æµ‹è¯•
python test_offline.py

# æŸ¥çœ‹æ ·æœ¬æ•°æ®
python -c "from rtl_error_correction import create_sample_data; print(create_sample_data())"
```

---

## âš ï¸ é‡è¦è¯´æ˜ / Important Notes

### ä¸­æ–‡
- **å½“å‰ç‰ˆæœ¬**: è¿™æ˜¯ä¸€ä¸ªç ”ç©¶åŸå‹ï¼Œå±•ç¤ºæŠ€æœ¯å¯è¡Œæ€§
- **æ•°æ®çŠ¶å†µ**: éœ€è¦ç”¨æˆ·æ ¹æ®å…·ä½“éœ€æ±‚åˆ›å»ºçœŸå®çš„è®­ç»ƒæ•°æ®é›†
- **è®­ç»ƒå»ºè®®**: å»ºè®®æ”¶é›†è‡³å°‘10,000ä¸ªRTLé”™è¯¯-ä¿®æ­£å¯¹è¿›è¡ŒçœŸå®è®­ç»ƒ
- **åŠŸèƒ½å®Œæ•´æ€§**: æ‰€æœ‰å¿…è¦çš„ä»£ç å’Œå·¥å…·éƒ½å·²æä¾›ï¼Œåªéœ€è¦æ·»åŠ çœŸå®æ•°æ®

### English
- **Current Version**: This is a research prototype demonstrating technical feasibility
- **Data Status**: Users need to create real training datasets based on specific requirements
- **Training Recommendation**: Recommend collecting at least 10,000 RTL error-correction pairs for real training
- **Functionality**: All necessary code and tools are provided, only need to add real data

---

## ğŸ“ è·å–å¸®åŠ© / Get Help

å¦‚æœéœ€è¦ååŠ©åˆ›å»ºæ•°æ®é›†æˆ–æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·ï¼š
If you need help creating datasets or have other questions, please:

1. æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£ / Check project documentation
2. è¿è¡Œç°æœ‰ç¤ºä¾‹ / Run existing examples
3. å‚è€ƒå…¶ä»–ç±»ä¼¼é¡¹ç›®çš„æ•°æ®é›†æ ¼å¼ / Refer to similar projects' dataset formats