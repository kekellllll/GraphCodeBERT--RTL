#!/usr/bin/env python3
"""
RTLæ¨¡å‹æ•°æ®çŠ¶å†µæ£€æŸ¥å·¥å…· / RTL Model Data Status Checker

è¯¥è„šæœ¬æ£€æŸ¥å¹¶æ˜¾ç¤ºå½“å‰RTLæ¨¡å‹çš„æ•°æ®çŠ¶å†µï¼ŒåŒ…æ‹¬ï¼š
This script checks and displays the current data status of RTL model, including:
- ç°æœ‰æ ·æœ¬æ•°æ® / Existing sample data
- æ•°æ®é›†ä½ç½® / Dataset locations  
- è®­ç»ƒæ•°æ®éœ€æ±‚ / Training data requirements
- ç”Ÿæˆå·¥å…·çŠ¶æ€ / Generation tool status

ä½¿ç”¨æ–¹æ³• / Usage:
python check_data_status.py
"""

import os
import sys
import json
import glob
from pathlib import Path

# Add current directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def check_sample_data():
    """æ£€æŸ¥å†…ç½®æ ·æœ¬æ•°æ®"""
    print("ğŸ” æ£€æŸ¥å†…ç½®æ ·æœ¬æ•°æ® / Checking Built-in Sample Data")
    print("=" * 60)
    
    try:
        # Import the sample data creation function
        rtl_path = os.path.join(os.path.dirname(__file__), 'GraphCodeBERT', 'rtl_error_localization')
        sys.path.insert(0, rtl_path)
        from rtl_error_correction import create_sample_data
        
        samples = create_sample_data()
        print(f"ğŸ“Š å†…ç½®æ ·æœ¬æ•°é‡ / Built-in Samples: {len(samples)}")
        print(f"ğŸ“ ä»£ç ä½ç½® / Code Location: GraphCodeBERT/rtl_error_localization/rtl_error_correction.py")
        print(f"ğŸ”§ å‡½æ•°åç§° / Function Name: create_sample_data()")
        
        print(f"\nğŸ“ æ ·æœ¬è¯¦æƒ… / Sample Details:")
        for i, sample in enumerate(samples, 1):
            print(f"\n  æ ·æœ¬ {i} / Sample {i}:")
            print(f"    é”™è¯¯ä»£ç  / Buggy:   {sample['buggy_code']}")
            print(f"    æ­£ç¡®ä»£ç  / Correct: {sample['correct_code']}")
            print(f"    æ³¨é‡Š / Comments: {sample['comments']}")
        
        return len(samples)
    except Exception as e:
        print(f"âŒ æ— æ³•åŠ è½½æ ·æœ¬æ•°æ® / Cannot load sample data: {e}")
        return 0

def check_generated_datasets():
    """æ£€æŸ¥ç”Ÿæˆçš„æ•°æ®é›†"""
    print("\nğŸ—‚ï¸  æ£€æŸ¥ç”Ÿæˆçš„æ•°æ®é›† / Checking Generated Datasets")
    print("=" * 60)
    
    # Check common dataset locations
    dataset_locations = [
        'datasets/rtl_error_correction',
        'datasets/rtl_training', 
        'datasets/sample_rtl_data',
        '../datasets/rtl_error_correction',
        '../datasets/rtl_training',
        '../datasets/sample_rtl_data'
    ]
    
    found_datasets = []
    for location in dataset_locations:
        if os.path.exists(location):
            files = glob.glob(os.path.join(location, "*.json*"))
            if files:
                found_datasets.append((location, files))
    
    if found_datasets:
        print("âœ… å‘ç°ç”Ÿæˆçš„æ•°æ®é›† / Found Generated Datasets:")
        for location, files in found_datasets:
            print(f"\nğŸ“ ä½ç½® / Location: {location}")
            for file in files:
                try:
                    if file.endswith('.json'):
                        with open(file, 'r') as f:
                            data = json.load(f)
                            count = len(data) if isinstance(data, list) else 1
                    elif file.endswith('.jsonl'):
                        with open(file, 'r') as f:
                            count = sum(1 for _ in f)
                    else:
                        count = "Unknown"
                    
                    print(f"  ğŸ“„ {os.path.basename(file)}: {count} æ ·æœ¬")
                except Exception as e:
                    print(f"  ğŸ“„ {os.path.basename(file)}: æ— æ³•è¯»å– / Cannot read")
        
        return len(found_datasets)
    else:
        print("âš ï¸  æœªæ‰¾åˆ°ç”Ÿæˆçš„æ•°æ®é›† / No Generated Datasets Found")
        print("ğŸ’¡ æç¤º / Tip: ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”Ÿæˆæ•°æ®é›† / Use following command to generate:")
        print("   python tools/generate_rtl_dataset.py --output datasets/rtl_training --size 1000")
        return 0

def check_tools():
    """æ£€æŸ¥å¯ç”¨å·¥å…·"""
    print("\nğŸ› ï¸  æ£€æŸ¥å¯ç”¨å·¥å…· / Checking Available Tools") 
    print("=" * 60)
    
    tools_dir = "tools"
    if not os.path.exists(tools_dir):
        tools_dir = "../tools" 
    
    if os.path.exists(tools_dir):
        dataset_generator = os.path.join(tools_dir, "generate_rtl_dataset.py")
        if os.path.exists(dataset_generator):
            print(f"âœ… æ•°æ®é›†ç”Ÿæˆå·¥å…· / Dataset Generator: {dataset_generator}")
            print(f"ğŸš€ ä½¿ç”¨æ–¹æ³• / Usage:")
            print(f"   python {dataset_generator} --help")
            print(f"   python {dataset_generator} --output datasets/rtl_training --size 1000")
            return True
        else:
            print(f"âŒ æ•°æ®é›†ç”Ÿæˆå·¥å…·æœªæ‰¾åˆ° / Dataset Generator Not Found")
            return False
    else:
        print(f"âŒ å·¥å…·ç›®å½•æœªæ‰¾åˆ° / Tools Directory Not Found: {tools_dir}")
        return False

def show_training_requirements():
    """æ˜¾ç¤ºè®­ç»ƒæ•°æ®éœ€æ±‚"""
    print("\nğŸ“‹ è®­ç»ƒæ•°æ®éœ€æ±‚ / Training Data Requirements")
    print("=" * 60)
    
    requirements = {
        "ç ”ç©¶åŸå‹ / Research Prototype": "100-1,000 æ ·æœ¬",
        "åŸºç¡€æ¨¡å‹ / Basic Model": "1,000-5,000 æ ·æœ¬", 
        "ç”Ÿäº§çº§æ¨¡å‹ / Production Model": "10,000+ æ ·æœ¬",
        "é«˜è´¨é‡æ¨¡å‹ / High Quality Model": "50,000+ æ ·æœ¬"
    }
    
    for level, count in requirements.items():
        print(f"  {level}: {count}")
    
    print(f"\nğŸ“Š æ¨èæ•°æ®æ ¼å¼ / Recommended Data Format:")
    print(f"  JSONLæ ¼å¼ï¼Œæ¯è¡ŒåŒ…å« / JSONL format, each line contains:")
    print(f"  - buggy_code: é”™è¯¯çš„RTLä»£ç ")
    print(f"  - correct_code: æ­£ç¡®çš„RTLä»£ç ") 
    print(f"  - comments: åŠŸèƒ½è¯´æ˜")
    print(f"  - error_type: é”™è¯¯ç±»å‹")

def show_current_status_summary():
    """æ˜¾ç¤ºå½“å‰çŠ¶æ€æ€»ç»“"""
    print("\nğŸ“ˆ å½“å‰çŠ¶æ€æ€»ç»“ / Current Status Summary")
    print("=" * 60)
    
    print("ğŸ”´ å½“å‰é˜¶æ®µ / Current Stage: æ¼”ç¤ºå’Œæ¦‚å¿µéªŒè¯ / Demo & Proof of Concept")
    print("ğŸ“Š å¯ç”¨æ•°æ® / Available Data: 3ä¸ªç¡¬ç¼–ç æ ·æœ¬ / 3 hardcoded samples")
    print("ğŸ¯ ç”¨é€” / Purpose: åŠŸèƒ½æ¼”ç¤ºï¼Œæ¶æ„éªŒè¯ / Feature demo, architecture validation")
    print("âš ï¸  é™åˆ¶ / Limitations: ä¸é€‚ç”¨äºå®é™…è®­ç»ƒ / Not suitable for real training")
    
    print(f"\nâœ… ä¸‹ä¸€æ­¥è¡ŒåŠ¨ / Next Steps:")
    print(f"  1. ä½¿ç”¨æ•°æ®ç”Ÿæˆå·¥å…·åˆ›å»ºæ›´å¤šæ ·æœ¬ / Use generation tool for more samples")
    print(f"  2. æ”¶é›†çœŸå®çš„RTLé”™è¯¯æ•°æ® / Collect real RTL error data")
    print(f"  3. æ‰‹åŠ¨æ ‡æ³¨é”™è¯¯-ä¿®æ­£å¯¹ / Manually annotate error-correction pairs")
    print(f"  4. éªŒè¯æ•°æ®è´¨é‡ / Validate data quality")
    print(f"  5. å¼€å§‹çœŸå®è®­ç»ƒ / Start real training")

def main():
    print("ğŸš€ RTLæ¨¡å‹æ•°æ®çŠ¶å†µæ£€æŸ¥æŠ¥å‘Š / RTL Model Data Status Report")
    print("=" * 80)
    
    # Check built-in samples
    sample_count = check_sample_data()
    
    # Check generated datasets 
    dataset_count = check_generated_datasets()
    
    # Check available tools
    tools_available = check_tools()
    
    # Show training requirements
    show_training_requirements()
    
    # Show current status summary
    show_current_status_summary()
    
    # Final recommendation
    print(f"\nğŸ’¡ å»ºè®® / Recommendations:")
    if sample_count > 0 and tools_available:
        print(f"âœ… åŸºç¡€è®¾æ–½å®Œå¤‡ï¼Œå¯ä»¥å¼€å§‹æ•°æ®ç”Ÿæˆå’Œæ”¶é›†")
        print(f"âœ… Infrastructure ready, can start data generation and collection")
    else:
        print(f"âš ï¸  éœ€è¦ä¿®å¤åŸºç¡€è®¾æ–½é—®é¢˜åå†è¿›è¡Œæ•°æ®å‡†å¤‡") 
        print(f"âš ï¸  Need to fix infrastructure issues before data preparation")
    
    print(f"\nğŸ“š è¯¦ç»†ä¿¡æ¯å‚è€ƒ / For detailed information see:")
    print(f"   - RTL_DATA_SOURCES.md (å®Œæ•´æ•°æ®æºè¯´æ˜)")
    print(f"   - tools/generate_rtl_dataset.py (æ•°æ®ç”Ÿæˆå·¥å…·)")
    print(f"   - GraphCodeBERT/rtl_error_localization/README.md (ä½¿ç”¨æŒ‡å—)")

if __name__ == "__main__":
    main()