#!/usr/bin/env python3
"""
RTLæ•°æ®é›†ç”Ÿæˆå·¥å…· / RTL Dataset Generation Tool

è¯¥å·¥å…·ç”¨äºç”ŸæˆRTLé”™è¯¯ä¿®æ­£è®­ç»ƒæ•°æ®é›†ï¼ŒåŒ…æ‹¬ï¼š
This tool generates RTL error correction training datasets, including:
- é”™è¯¯çš„Verilogä»£ç  / Buggy Verilog code
- å¯¹åº”çš„æ­£ç¡®ä»£ç  / Corresponding correct code  
- ä»£ç æ³¨é‡Š / Code comments
- é”™è¯¯ç±»å‹æ ‡æ³¨ / Error type annotations

ä½¿ç”¨æ–¹æ³• / Usage:
python generate_rtl_dataset.py --output datasets/rtl_training --size 1000
"""

import os
import json
import random
import argparse
from typing import List, Dict, Tuple
from datetime import datetime

class RTLDatasetGenerator:
    """RTLé”™è¯¯ä¿®æ­£æ•°æ®é›†ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.error_types = [
            "unnecessary_arithmetic",
            "missing_parentheses", 
            "blocking_assignment",
            "clock_sensitivity",
            "wire_reg_mismatch",
            "port_connection",
            "syntax_error",
            "logic_error"
        ]
        
        # åŸºç¡€æ¨¡å—æ¨¡æ¿
        self.module_templates = [
            {
                "name": "simple_assign",
                "correct": "module {name}(input {in_sig}, output {out_sig}); assign {out_sig} = {in_sig}; endmodule",
                "buggy": "module {name}(input {in_sig}, output {out_sig}); assign {out_sig} = {in_sig} + 1; endmodule", 
                "error_type": "unnecessary_arithmetic",
                "comment": "Simple wire connection module"
            },
            {
                "name": "logic_gate", 
                "correct": "module {name}(input {in1}, {in2}, output {out}); assign {out} = ({in1} & {in2}) | {in3}; endmodule",
                "buggy": "module {name}(input {in1}, {in2}, output {out}); assign {out} = {in1} & {in2} | {in3}; endmodule",
                "error_type": "missing_parentheses", 
                "comment": "Logic gate with proper operator precedence"
            },
            {
                "name": "dff_register",
                "correct": "always @(posedge clk) begin q <= d; end",
                "buggy": "always @(posedge clk) begin q = d; end", 
                "error_type": "blocking_assignment",
                "comment": "D flip-flop register with non-blocking assignment"
            },
            {
                "name": "counter",
                "correct": "always @(posedge clk, negedge rst_n) begin if (!rst_n) count <= 0; else count <= count + 1; end",
                "buggy": "always @(posedge clk) begin if (!rst_n) count <= 0; else count <= count + 1; end",
                "error_type": "clock_sensitivity", 
                "comment": "Counter with proper reset sensitivity"
            },
            {
                "name": "mux_2to1",
                "correct": "assign out = sel ? in1 : in0;",
                "buggy": "assign out = sel ? in1; in0;",
                "error_type": "syntax_error",
                "comment": "2-to-1 multiplexer with conditional assignment" 
            }
        ]
        
        # ä¿¡å·åç§°é€‰é¡¹
        self.signal_names = {
            'input': ['a', 'b', 'c', 'd', 'in', 'data', 'x', 'y', 'clk', 'rst', 'en'],
            'output': ['out', 'result', 'q', 'y', 'sum', 'prod', 'valid'], 
            'module': ['test', 'example', 'demo', 'simple', 'basic', 'logic', 'arith']
        }

    def generate_signals(self) -> Dict[str, str]:
        """ç”Ÿæˆéšæœºä¿¡å·åç§°"""
        return {
            'name': random.choice(self.signal_names['module']) + f"_{random.randint(1, 999)}",
            'in_sig': random.choice(self.signal_names['input']),
            'out_sig': random.choice(self.signal_names['output']),
            'in1': random.choice(self.signal_names['input']),
            'in2': random.choice(self.signal_names['input']), 
            'in3': random.choice(self.signal_names['input']),
            'out': random.choice(self.signal_names['output'])
        }

    def generate_single_example(self) -> Dict[str, str]:
        """ç”Ÿæˆå•ä¸ªè®­ç»ƒæ ·æœ¬"""
        template = random.choice(self.module_templates)
        signals = self.generate_signals()
        
        try:
            correct_code = template['correct'].format(**signals)
            buggy_code = template['buggy'].format(**signals) 
        except KeyError:
            # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä¿¡å·å
            default_signals = {
                'name': 'test_module',
                'in_sig': 'a', 'out_sig': 'b',
                'in1': 'in1', 'in2': 'in2', 'in3': 'in3', 'out': 'out'
            }
            correct_code = template['correct'].format(**default_signals)
            buggy_code = template['buggy'].format(**default_signals)
        
        return {
            'buggy_code': buggy_code,
            'correct_code': correct_code,
            'comments': template['comment'],
            'error_type': template['error_type'],
            'template_name': template['name'],
            'generated_at': datetime.now().isoformat()
        }

    def generate_dataset(self, size: int) -> List[Dict[str, str]]:
        """ç”ŸæˆæŒ‡å®šå¤§å°çš„æ•°æ®é›†"""
        dataset = []
        for i in range(size):
            example = self.generate_single_example()
            example['id'] = i
            dataset.append(example)
        return dataset

    def save_dataset(self, dataset: List[Dict[str, str]], output_dir: str, split_name: str):
        """ä¿å­˜æ•°æ®é›†åˆ°æ–‡ä»¶"""
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜ä¸ºJSONLæ ¼å¼
        jsonl_file = os.path.join(output_dir, f"{split_name}.jsonl")
        with open(jsonl_file, 'w', encoding='utf-8') as f:
            for example in dataset:
                f.write(json.dumps(example, ensure_ascii=False) + '\n')
        
        # ä¿å­˜ä¸ºJSONæ ¼å¼ 
        json_file = os.path.join(output_dir, f"{split_name}.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å·²ä¿å­˜ {len(dataset)} ä¸ªæ ·æœ¬åˆ° {split_name}.jsonl å’Œ {split_name}.json")

def main():
    parser = argparse.ArgumentParser(description='ç”ŸæˆRTLé”™è¯¯ä¿®æ­£æ•°æ®é›†')
    parser.add_argument('--output', type=str, default='datasets/rtl_error_correction',
                      help='è¾“å‡ºç›®å½•è·¯å¾„') 
    parser.add_argument('--size', type=int, default=1000,
                      help='ç”Ÿæˆçš„æ€»æ ·æœ¬æ•°')
    parser.add_argument('--train_ratio', type=float, default=0.7,
                      help='è®­ç»ƒé›†æ¯”ä¾‹')
    parser.add_argument('--valid_ratio', type=float, default=0.15, 
                      help='éªŒè¯é›†æ¯”ä¾‹')
    parser.add_argument('--test_ratio', type=float, default=0.15,
                      help='æµ‹è¯•é›†æ¯”ä¾‹')
    
    args = parser.parse_args()
    
    # éªŒè¯æ¯”ä¾‹
    total_ratio = args.train_ratio + args.valid_ratio + args.test_ratio
    if abs(total_ratio - 1.0) > 0.001:
        print(f"âŒ é”™è¯¯ï¼šæ•°æ®é›†åˆ†å‰²æ¯”ä¾‹æ€»å’Œåº”ä¸º1.0ï¼Œå½“å‰ä¸º{total_ratio}")
        return
    
    generator = RTLDatasetGenerator()
    
    print(f"ğŸš€ å¼€å§‹ç”ŸæˆRTLé”™è¯¯ä¿®æ­£æ•°æ®é›†...")
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {args.size}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output}")
    print(f"ğŸ“ˆ æ•°æ®åˆ†å‰²: è®­ç»ƒ{args.train_ratio:.0%}, éªŒè¯{args.valid_ratio:.0%}, æµ‹è¯•{args.test_ratio:.0%}")
    
    # ç”Ÿæˆå®Œæ•´æ•°æ®é›†
    full_dataset = generator.generate_dataset(args.size)
    
    # è®¡ç®—åˆ†å‰²å¤§å°
    train_size = int(args.size * args.train_ratio)
    valid_size = int(args.size * args.valid_ratio) 
    test_size = args.size - train_size - valid_size
    
    # éšæœºæ‰“ä¹±å¹¶åˆ†å‰²æ•°æ®
    random.shuffle(full_dataset)
    train_set = full_dataset[:train_size]
    valid_set = full_dataset[train_size:train_size + valid_size]
    test_set = full_dataset[train_size + valid_size:]
    
    # ä¿å­˜æ•°æ®é›†
    generator.save_dataset(train_set, args.output, 'train')
    generator.save_dataset(valid_set, args.output, 'valid') 
    generator.save_dataset(test_set, args.output, 'test')
    
    # ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_samples': args.size,
        'train_samples': len(train_set),
        'valid_samples': len(valid_set), 
        'test_samples': len(test_set),
        'error_types': generator.error_types,
        'generation_time': datetime.now().isoformat(),
        'templates_used': len(generator.module_templates)
    }
    
    stats_file = os.path.join(args.output, 'dataset_stats.json')
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“‹ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_file}")
    print(f"ğŸ” é”™è¯¯ç±»å‹è¦†ç›–: {len(generator.error_types)} ç§")
    
    # æ˜¾ç¤ºæ ·æœ¬ç¤ºä¾‹
    print(f"\nğŸ“ æ ·æœ¬ç¤ºä¾‹:")
    example = train_set[0]
    print(f"é”™è¯¯ä»£ç : {example['buggy_code']}")
    print(f"æ­£ç¡®ä»£ç : {example['correct_code']}")
    print(f"é”™è¯¯ç±»å‹: {example['error_type']}")
    print(f"æ³¨é‡Š: {example['comments']}")

if __name__ == "__main__":
    main()